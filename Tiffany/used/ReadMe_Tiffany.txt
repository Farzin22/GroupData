Get GDSIDs

To access the code base for this project, please go to the following web site: https://github.com/bcl2group/GroupData/tree/master/Tiffany.
Download the file named GEOpipeline.R, and run it in the R program [3].  The disease list I used was the file called All_diseasesToGDSIDs.txt.  To find the GDSIDs of the experiments associated with the diseases, I went to the web site http://www.ncbi.nlm.nih.gov/gds, and searched for the disease, and looked at the DataSets available for the disease.  The GDSIDs are then inputted into the R file, for the variable called ids as a string with a comma between each id.  Then run the script.  You will find files called Myelitis_singlenet_25percent.txt and Myelitis_25percent.txt.  You will then need to rename the two, changing the .txt extension to .arff.  A change from Myelitis to the disease name is also suggested.  From here, simply open the .arff file, and the Weka explorer should open.  

To gather the data, we looked at each individual disease and searched for relevant DataSets on the GEO database.  We then screened the results so we had the identification numbers of a series of DataSets that we know are relevant.  This step is necessary because of two things: 1) sometimes the system returns odd results, such as an experiment on Down syndrome mixed in with the results of lung diseases and 2) we want to confuse the system as little as possible, so we filter out experiments that are run on two or more diseases and focus only on the ones dealing only with the disease in question, for example Alzheimer’s syndrome is commonly analyzed alongside schizophrenia.  
We then input the identification numbers of the experiments (called GDSIDS for GEO database identifications) into the pipeline and allow it to create the arff file for both Bayesian single net and Bayesian multinet models.  
At this step it is necessary to further narrow down the number of diseases used.   Because the pipeline does its own filtering to find relevant experiments, we may end up with only one DataSet left after the pipeline, or even none.  These diseases must be discarded because with both, the model for both the multinet and the single net Bayesian network is identical, and therefore, the external cross validation is also identical, leaving us with no relevant information, and instead data that can heavily skew our decision on whether to use multinets or single net Bayesian networks greatly. 
If the disease survives the filtering step above, we then run the Weka program on it, using the Weka explorer to run the external cross validation.  To do that, we used the classify tab in the Weka explorer, and picked the Attribute Selected Classifier under classifiers of the type meta, then for the details of this classifier, we used the Naïve Bayes classifier, with an evaluator of wrapper subset evaluation, and a search of linear forward selection, which is an extension of the best first search.

We then ran the classifier on cross-validation with three folds, with the class (Control or Infected in the case of single net Bayesian network and Control and a list of experiments for the multinet Bayesian network) as the subject of interest in the Bayesian network.  Running the external cross-validation with three folds means that we create the model with two thirds of the data, and testing with the last third of the data available.  
 
We then recorded the AUROC data for each of the models for comparison later, the number of DataSets that survived the pipeline’s filter, the number of attributes (genes) associated with the disease, and the number of samples we have to build and test the model with for future use.  
To find correlation, we used scatter plots to find the relationship between the difference in AUROC values and the other recorded data: total number of experiments, number of experiments before the pipeline, number of experiments after the pipeline, number of features, and number of samples available.  Once we had some likely relationships from the plots, we ran t-tests to determine if these relationships we see are statistically significant.   
